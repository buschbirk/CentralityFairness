#!/bin/bash

#SBATCH -J sparkcluster
#SBATCH -t 1410 # runtime to request !!! in minutes !!!
#SBATCH --output=/home/laal/MAG/CentralityFairness/JOB_OUTPUTS/job.%j.out 
#SBATCH --cpus-per-task=4        # Schedule 8 cores (includes hyperthreading)
#SBATCH --time=23:30:00          # Run time (hh:mm:ss) - run for one hour max
#SBATCH -N 3
#SBATCH --ntasks-per-core=1

# setup the spark paths

echo "Running on $(hostname):"


module load Anaconda3
. $(conda info --base)/etc/profile.d/conda.sh
conda activate torchenv

python /home/laal/MAG/CentralityFairness/clusterscript.py

conda deactivate

##### #SBATCH --mem-per-cpu=8000