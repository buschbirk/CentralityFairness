#!/bin/env
#SBATCH -J sparkcluster
#SBATCH -t 30 # runtime to request !!! in minutes !!!
#SBATCH -o sparkcluster-%J.log # output extra o means overwrite
#SBATCH -n 2 # requesting n tasks
#SBATCH -c 1
#SBATCH --mem-per-cpu=2000 
#SBATCH -N 2
#SBATCH --ntasks-per-core=1

# setup the spark paths

echo "Running on $(hostname):"

module load Anaconda3
. $(conda info --base)/etc/profile.d/conda.sh
conda activate torchenv


python /home/laal/MAG/CentralityFairness/clusterscript.py

