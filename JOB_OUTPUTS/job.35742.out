Running on desktop1:
FINISHED SETTIN UP CLUSTER
21/02/25 11:55:01 WARN Utils: Your hostname, desktop1 resolves to a loopback address: 127.0.0.1; using 172.16.16.101 instead (on interface eno1)
21/02/25 11:55:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Ivy Default Cache set to: /home/laal/.ivy2/cache
The jars for the packages stored in: /home/laal/.ivy2/jars
:: loading settings :: url = jar:file:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-bf5fc7e1-c58f-4993-b128-c0e11f01217a;1.0
	confs: [default]
	found graphframes#graphframes;0.3.0-spark2.0-s_2.11 in spark-packages
	found com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central
	found com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central
	found org.scala-lang#scala-reflect;2.11.0 in central
	found org.slf4j#slf4j-api;1.7.7 in central
:: resolution report :: resolve 256ms :: artifacts dl 13ms
	:: modules in use:
	com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]
	com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]
	graphframes#graphframes;0.3.0-spark2.0-s_2.11 from spark-packages in [default]
	org.scala-lang#scala-reflect;2.11.0 from central in [default]
	org.slf4j#slf4j-api;1.7.7 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-bf5fc7e1-c58f-4993-b128-c0e11f01217a
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/16ms)
21/02/25 11:55:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
21/02/25 11:55:04 WARN SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!
['NAME STATE JOBID', 'MAG_attribs RUNNING 35731', 'MAG_attribs RUNNING 35742', 'hebbian_weights_submit RUNNING 35734', 'hebbian_weights_submit RUNNING 35688', 'agg RUNNING 35571', 'agg RUNNING 35570', 'agg RUNNING 35569', 'agg RUNNING 35568', 'pen RUNNING 35567', 'pen RUNNING 35566', 'pen RUNNING 35565', 'pen RUNNING 35564', 'pen RUNNING 35563', 'agg RUNNING 35562', '']
Traceback (most recent call last):
  File "/home/laal/MAG/CentralityFairness/MAG_attributes_cluster.py", line 243, in <module>
    citations = citation_edges(mag)
  File "/home/laal/MAG/CentralityFairness/MAG_attributes_cluster.py", line 132, in citation_edges
    paper_root_field = mag.getDataframe('PaperRootField')
  File "/home/laal/MAG/CentralityFairness/MAG.py", line 52, in getDataframe
    .load(self.data_folderpath + self.streams[streamName][0])
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 178, in load
    return self._df(self._jreader.load(path))
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/py4j/java_gateway.py", line 1305, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Path does not exist: file:/home/laal/MAG/DATA/PaperRootField.txt;
