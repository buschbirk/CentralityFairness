Running on desktop1:
INFO:sparkhpc.sparkjob:master command: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-master.sh
INFO:sparkhpc.sparkjob:[[92mstart_cluster] [0mmaster running at spark://172.16.16.101:7077
INFO:sparkhpc.sparkjob:[[92mstart_cluster] [0mmaster UI available at http://desktop1.hpc.itu.dk:8080
What is going on
I GOT THE SCHEDULER
slurm
master_command: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-master.sh
['desktop1', 'desktop2', 'desktop3']
INFO:sparkhpc.sparkjob:slaves command: srun /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-slave.sh spark://172.16.16.101:7077 -c 4
INFO:sparkhpc.sparkjob:XXX SLAVES SLAVES: srun /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-slave.sh spark://172.16.16.101:7077 -c 4
starting org.apache.spark.deploy.worker.Worker, logging to /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/logs/spark-laal-org.apache.spark.deploy.worker.Worker-1-desktop1.out
starting org.apache.spark.deploy.worker.Worker, logging to /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/logs/spark-laal-org.apache.spark.deploy.worker.Worker-1-desktop1.out
starting org.apache.spark.deploy.worker.Worker, logging to /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/logs/spark-laal-org.apache.spark.deploy.worker.Worker-1-desktop1.out
Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java -cp /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://172.16.16.101:7077 -c 4
========================================
Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java -cp /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://172.16.16.101:7077 -c 4
========================================
Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java -cp /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://172.16.16.101:7077 -c 4
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/28 01:57:44 INFO Worker: Started daemon with process name: 19603@desktop1
21/02/28 01:57:44 INFO SignalUtils: Registered signal handler for TERM
21/02/28 01:57:44 INFO SignalUtils: Registered signal handler for HUP
21/02/28 01:57:44 INFO SignalUtils: Registered signal handler for INT
21/02/28 01:57:44 WARN Utils: Your hostname, desktop1 resolves to a loopback address: 127.0.0.1; using 172.16.16.101 instead (on interface eno1)
21/02/28 01:57:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/28 01:57:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/28 01:57:45 INFO SecurityManager: Changing view acls to: laal
21/02/28 01:57:45 INFO SecurityManager: Changing modify acls to: laal
21/02/28 01:57:45 INFO SecurityManager: Changing view acls groups to: 
21/02/28 01:57:45 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 01:57:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 01:57:45 INFO Utils: Successfully started service 'sparkWorker' on port 35812.
21/02/28 01:57:45 INFO Worker: Starting Spark worker 172.16.16.101:35812 with 4 cores, 23.4 GiB RAM
21/02/28 01:57:45 INFO Worker: Running Spark version 3.0.2
21/02/28 01:57:45 INFO Worker: Spark home: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7
21/02/28 01:57:45 INFO ResourceUtils: ==============================================================
21/02/28 01:57:45 INFO ResourceUtils: Resources for spark.worker:

21/02/28 01:57:45 INFO ResourceUtils: ==============================================================
21/02/28 01:57:45 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/02/28 01:57:45 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://desktop1.hpc.itu.dk:8081
21/02/28 01:57:45 INFO Worker: Connecting to master 172.16.16.101:7077...
21/02/28 01:57:45 INFO TransportClientFactory: Successfully created connection to /172.16.16.101:7077 after 23 ms (0 ms spent in bootstraps)
21/02/28 01:57:46 INFO Worker: Successfully registered with master spark://172.16.16.101:7077
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/28 01:57:47 INFO Worker: Started daemon with process name: 31465@desktop3
21/02/28 01:57:47 INFO SignalUtils: Registered signal handler for TERM
21/02/28 01:57:47 INFO SignalUtils: Registered signal handler for HUP
21/02/28 01:57:47 INFO SignalUtils: Registered signal handler for INT
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/28 01:57:47 INFO Worker: Started daemon with process name: 27566@desktop2
21/02/28 01:57:47 INFO SignalUtils: Registered signal handler for TERM
21/02/28 01:57:47 WARN Utils: Your hostname, desktop3 resolves to a loopback address: 127.0.0.1; using 172.16.16.103 instead (on interface eno1)
21/02/28 01:57:47 INFO SignalUtils: Registered signal handler for HUP
21/02/28 01:57:47 INFO SignalUtils: Registered signal handler for INT
21/02/28 01:57:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/28 01:57:47 WARN Utils: Your hostname, desktop2 resolves to a loopback address: 127.0.0.1; using 172.16.16.102 instead (on interface eno1)
21/02/28 01:57:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/28 01:57:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/28 01:57:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/28 01:57:47 INFO SecurityManager: Changing view acls to: laal
21/02/28 01:57:47 INFO SecurityManager: Changing modify acls to: laal
21/02/28 01:57:47 INFO SecurityManager: Changing view acls groups to: 
21/02/28 01:57:47 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 01:57:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 01:57:47 INFO SecurityManager: Changing view acls to: laal
21/02/28 01:57:47 INFO SecurityManager: Changing modify acls to: laal
21/02/28 01:57:47 INFO SecurityManager: Changing view acls groups to: 
21/02/28 01:57:47 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 01:57:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 01:57:48 INFO Utils: Successfully started service 'sparkWorker' on port 42397.
21/02/28 01:57:48 INFO Utils: Successfully started service 'sparkWorker' on port 43968.
21/02/28 01:57:48 INFO Worker: Starting Spark worker 172.16.16.103:42397 with 4 cores, 23.4 GiB RAM
21/02/28 01:57:48 INFO Worker: Running Spark version 3.0.2
21/02/28 01:57:48 INFO Worker: Spark home: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7
21/02/28 01:57:48 INFO ResourceUtils: ==============================================================
21/02/28 01:57:48 INFO ResourceUtils: Resources for spark.worker:

21/02/28 01:57:48 INFO ResourceUtils: ==============================================================
21/02/28 01:57:48 INFO Worker: Starting Spark worker 172.16.16.102:43968 with 4 cores, 23.4 GiB RAM
21/02/28 01:57:48 INFO Worker: Running Spark version 3.0.2
21/02/28 01:57:48 INFO Worker: Spark home: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7
21/02/28 01:57:48 INFO ResourceUtils: ==============================================================
21/02/28 01:57:48 INFO ResourceUtils: Resources for spark.worker:

21/02/28 01:57:48 INFO ResourceUtils: ==============================================================
21/02/28 01:57:48 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/02/28 01:57:48 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://desktop3.hpc.itu.dk:8081
21/02/28 01:57:48 INFO Worker: Connecting to master 172.16.16.101:7077...
21/02/28 01:57:48 INFO TransportClientFactory: Successfully created connection to /172.16.16.101:7077 after 30 ms (0 ms spent in bootstraps)
21/02/28 01:57:48 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/02/28 01:57:48 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://desktop2.hpc.itu.dk:8081
21/02/28 01:57:48 INFO Worker: Connecting to master 172.16.16.101:7077...
21/02/28 01:57:48 INFO Worker: Successfully registered with master spark://172.16.16.101:7077
21/02/28 01:57:48 INFO TransportClientFactory: Successfully created connection to /172.16.16.101:7077 after 37 ms (0 ms spent in bootstraps)
21/02/28 01:57:49 INFO Worker: Successfully registered with master spark://172.16.16.101:7077
21/02/28 01:59:11 INFO Worker: Asked to launch executor app-20210228015911-0000/0 for pyspark-shell
21/02/28 01:59:11 INFO Worker: Asked to launch executor app-20210228015911-0000/1 for pyspark-shell
21/02/28 01:59:11 INFO Worker: Asked to launch executor app-20210228015911-0000/2 for pyspark-shell
21/02/28 01:59:11 INFO SecurityManager: Changing view acls to: laal
21/02/28 01:59:11 INFO SecurityManager: Changing modify acls to: laal
21/02/28 01:59:11 INFO SecurityManager: Changing view acls groups to: 
21/02/28 01:59:11 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 01:59:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 01:59:11 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=40598" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:40598" "--executor-id" "0" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228015911-0000" "--worker-url" "spark://Worker@172.16.16.103:42397"
21/02/28 01:59:12 INFO SecurityManager: Changing view acls to: laal
21/02/28 01:59:12 INFO SecurityManager: Changing modify acls to: laal
21/02/28 01:59:12 INFO SecurityManager: Changing view acls groups to: 
21/02/28 01:59:12 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 01:59:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 01:59:12 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=40598" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:40598" "--executor-id" "1" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228015911-0000" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 01:59:13 INFO SecurityManager: Changing view acls to: laal
21/02/28 01:59:13 INFO SecurityManager: Changing modify acls to: laal
21/02/28 01:59:13 INFO SecurityManager: Changing view acls groups to: 
21/02/28 01:59:13 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 01:59:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 01:59:13 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=40598" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:40598" "--executor-id" "2" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228015911-0000" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 10:38:49 INFO Worker: Asked to kill executor app-20210228015911-0000/1
21/02/28 10:38:49 INFO ExecutorRunner: Runner thread for executor app-20210228015911-0000/1 interrupted
21/02/28 10:38:49 INFO ExecutorRunner: Killing process!
21/02/28 10:38:49 INFO Worker: Asked to kill executor app-20210228015911-0000/0
21/02/28 10:38:49 INFO ExecutorRunner: Runner thread for executor app-20210228015911-0000/0 interrupted
21/02/28 10:38:49 INFO Worker: Asked to kill executor app-20210228015911-0000/2
21/02/28 10:38:49 INFO ExecutorRunner: Killing process!
21/02/28 10:38:49 INFO ExecutorRunner: Runner thread for executor app-20210228015911-0000/2 interrupted
21/02/28 10:38:49 INFO ExecutorRunner: Killing process!
21/02/28 10:38:50 INFO Worker: Executor app-20210228015911-0000/1 finished with state KILLED exitStatus 143
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228015911-0000, execId=1)
21/02/28 10:38:50 INFO Worker: Cleaning up local directories for application app-20210228015911-0000
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Application app-20210228015911-0000 removed, cleanupLocalDirs = true
21/02/28 10:38:50 INFO Worker: Executor app-20210228015911-0000/0 finished with state KILLED exitStatus 143
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228015911-0000, execId=0)
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Application app-20210228015911-0000 removed, cleanupLocalDirs = true
21/02/28 10:38:50 INFO Worker: Cleaning up local directories for application app-20210228015911-0000
21/02/28 10:38:50 INFO Worker: Executor app-20210228015911-0000/2 finished with state KILLED exitStatus 143
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228015911-0000, execId=2)
21/02/28 10:38:50 INFO ExternalShuffleBlockResolver: Application app-20210228015911-0000 removed, cleanupLocalDirs = true
21/02/28 10:38:50 INFO Worker: Cleaning up local directories for application app-20210228015911-0000
21/02/28 10:39:10 INFO Worker: Asked to launch executor app-20210228103910-0001/2 for pyspark-shell
21/02/28 10:39:10 INFO Worker: Asked to launch executor app-20210228103910-0001/0 for pyspark-shell
21/02/28 10:39:10 INFO Worker: Asked to launch executor app-20210228103910-0001/1 for pyspark-shell
21/02/28 10:39:11 INFO SecurityManager: Changing view acls to: laal
21/02/28 10:39:11 INFO SecurityManager: Changing modify acls to: laal
21/02/28 10:39:11 INFO SecurityManager: Changing view acls groups to: 
21/02/28 10:39:11 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 10:39:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 10:39:11 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=36750" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:36750" "--executor-id" "2" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228103910-0001" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 10:39:13 INFO SecurityManager: Changing view acls to: laal
21/02/28 10:39:13 INFO SecurityManager: Changing modify acls to: laal
21/02/28 10:39:13 INFO SecurityManager: Changing view acls groups to: 
21/02/28 10:39:13 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 10:39:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 10:39:13 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=36750" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:36750" "--executor-id" "1" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228103910-0001" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 10:39:13 INFO SecurityManager: Changing view acls to: laal
21/02/28 10:39:13 INFO SecurityManager: Changing modify acls to: laal
21/02/28 10:39:13 INFO SecurityManager: Changing view acls groups to: 
21/02/28 10:39:13 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 10:39:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 10:39:13 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=36750" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:36750" "--executor-id" "0" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228103910-0001" "--worker-url" "spark://Worker@172.16.16.103:42397"
21/02/28 10:44:37 INFO Worker: Asked to kill executor app-20210228103910-0001/1
21/02/28 10:44:37 INFO ExecutorRunner: Runner thread for executor app-20210228103910-0001/1 interrupted
21/02/28 10:44:37 INFO ExecutorRunner: Killing process!
21/02/28 10:44:37 INFO Worker: Asked to kill executor app-20210228103910-0001/0
21/02/28 10:44:37 INFO ExecutorRunner: Runner thread for executor app-20210228103910-0001/0 interrupted
21/02/28 10:44:37 INFO ExecutorRunner: Killing process!
21/02/28 10:44:37 INFO Worker: Asked to kill executor app-20210228103910-0001/2
21/02/28 10:44:37 INFO ExecutorRunner: Runner thread for executor app-20210228103910-0001/2 interrupted
21/02/28 10:44:37 INFO ExecutorRunner: Killing process!
21/02/28 10:44:37 INFO Worker: Executor app-20210228103910-0001/0 finished with state KILLED exitStatus 143
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228103910-0001, execId=0)
21/02/28 10:44:37 INFO Worker: Cleaning up local directories for application app-20210228103910-0001
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Application app-20210228103910-0001 removed, cleanupLocalDirs = true
21/02/28 10:44:37 INFO Worker: Executor app-20210228103910-0001/2 finished with state KILLED exitStatus 143
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228103910-0001, execId=2)
21/02/28 10:44:37 INFO Worker: Cleaning up local directories for application app-20210228103910-0001
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Application app-20210228103910-0001 removed, cleanupLocalDirs = true
21/02/28 10:44:37 INFO Worker: Executor app-20210228103910-0001/1 finished with state KILLED exitStatus 143
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228103910-0001, execId=1)
21/02/28 10:44:37 INFO Worker: Cleaning up local directories for application app-20210228103910-0001
21/02/28 10:44:37 INFO ExternalShuffleBlockResolver: Application app-20210228103910-0001 removed, cleanupLocalDirs = true
21/02/28 10:44:51 INFO Worker: Asked to launch executor app-20210228104451-0002/0 for pyspark-shell
21/02/28 10:44:51 INFO Worker: Asked to launch executor app-20210228104451-0002/1 for pyspark-shell
21/02/28 10:44:51 INFO Worker: Asked to launch executor app-20210228104451-0002/2 for pyspark-shell
21/02/28 10:44:51 INFO SecurityManager: Changing view acls to: laal
21/02/28 10:44:51 INFO SecurityManager: Changing modify acls to: laal
21/02/28 10:44:51 INFO SecurityManager: Changing view acls groups to: 
21/02/28 10:44:51 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 10:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 10:44:51 INFO SecurityManager: Changing view acls to: laal
21/02/28 10:44:51 INFO SecurityManager: Changing view acls to: laal
21/02/28 10:44:51 INFO SecurityManager: Changing modify acls to: laal
21/02/28 10:44:51 INFO SecurityManager: Changing modify acls to: laal
21/02/28 10:44:51 INFO SecurityManager: Changing view acls groups to: 
21/02/28 10:44:51 INFO SecurityManager: Changing view acls groups to: 
21/02/28 10:44:51 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 10:44:51 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 10:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 10:44:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 10:44:51 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=34566" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:34566" "--executor-id" "2" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228104451-0002" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 10:44:51 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=34566" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:34566" "--executor-id" "0" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228104451-0002" "--worker-url" "spark://Worker@172.16.16.103:42397"
21/02/28 10:44:51 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=34566" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:34566" "--executor-id" "1" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228104451-0002" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 11:33:57 INFO Worker: Executor app-20210228104451-0002/2 finished with state EXITED message Command exited with code 137 exitStatus 137
21/02/28 11:33:57 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
21/02/28 11:33:57 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228104451-0002, execId=2)
21/02/28 11:33:57 INFO Worker: Asked to launch executor app-20210228104451-0002/3 for pyspark-shell
21/02/28 11:33:57 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:33:57 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:33:57 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:33:57 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:33:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:33:57 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=34566" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:34566" "--executor-id" "3" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228104451-0002" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 11:34:01 INFO Worker: Executor app-20210228104451-0002/1 finished with state EXITED message Command exited with code 137 exitStatus 137
21/02/28 11:34:01 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
21/02/28 11:34:01 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228104451-0002, execId=1)
21/02/28 11:34:01 INFO Worker: Asked to launch executor app-20210228104451-0002/4 for pyspark-shell
21/02/28 11:34:01 INFO Worker: Executor app-20210228104451-0002/0 finished with state EXITED message Command exited with code 137 exitStatus 137
21/02/28 11:34:01 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
21/02/28 11:34:01 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228104451-0002, execId=0)
21/02/28 11:34:01 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:34:01 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:34:01 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:34:01 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:34:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:34:01 INFO Worker: Asked to launch executor app-20210228104451-0002/5 for pyspark-shell
21/02/28 11:34:01 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=34566" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:34566" "--executor-id" "4" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228104451-0002" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 11:34:02 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:34:02 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:34:02 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:34:02 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:34:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:34:02 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=34566" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:34566" "--executor-id" "5" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228104451-0002" "--worker-url" "spark://Worker@172.16.16.103:42397"
21/02/28 11:42:08 INFO Worker: Asked to kill executor app-20210228104451-0002/5
21/02/28 11:42:08 INFO Worker: Asked to kill executor app-20210228104451-0002/4
21/02/28 11:42:08 INFO ExecutorRunner: Runner thread for executor app-20210228104451-0002/5 interrupted
21/02/28 11:42:08 INFO Worker: Asked to kill executor app-20210228104451-0002/3
21/02/28 11:42:08 INFO ExecutorRunner: Killing process!
21/02/28 11:42:08 INFO ExecutorRunner: Runner thread for executor app-20210228104451-0002/3 interrupted
21/02/28 11:42:08 INFO ExecutorRunner: Killing process!
21/02/28 11:42:08 INFO ExecutorRunner: Runner thread for executor app-20210228104451-0002/4 interrupted
21/02/28 11:42:08 INFO ExecutorRunner: Killing process!
21/02/28 11:42:09 INFO Worker: Executor app-20210228104451-0002/4 finished with state KILLED exitStatus 143
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 4
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228104451-0002, execId=4)
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Application app-20210228104451-0002 removed, cleanupLocalDirs = true
21/02/28 11:42:09 INFO Worker: Cleaning up local directories for application app-20210228104451-0002
21/02/28 11:42:09 INFO Worker: Executor app-20210228104451-0002/3 finished with state KILLED exitStatus 143
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 3
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228104451-0002, execId=3)
21/02/28 11:42:09 INFO Worker: Cleaning up local directories for application app-20210228104451-0002
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Application app-20210228104451-0002 removed, cleanupLocalDirs = true
21/02/28 11:42:09 INFO Worker: Executor app-20210228104451-0002/5 finished with state KILLED exitStatus 143
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 5
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228104451-0002, execId=5)
21/02/28 11:42:09 INFO Worker: Cleaning up local directories for application app-20210228104451-0002
21/02/28 11:42:09 INFO ExternalShuffleBlockResolver: Application app-20210228104451-0002 removed, cleanupLocalDirs = true
21/02/28 11:46:15 INFO Worker: Asked to launch executor app-20210228114615-0003/0 for pyspark-shell
21/02/28 11:46:15 INFO Worker: Asked to launch executor app-20210228114615-0003/1 for pyspark-shell
21/02/28 11:46:15 INFO Worker: Asked to launch executor app-20210228114615-0003/2 for pyspark-shell
21/02/28 11:46:16 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:16 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:16 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:16 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "1" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 11:46:18 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:18 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "0" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.103:42397"
21/02/28 11:46:18 ERROR ExecutorRunner: Error running executor
java.io.IOException: Cannot run program "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" (in directory "/home/laal/MAG/TMP/work/app-20210228114615-0003/0"): error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:79)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 2 more
21/02/28 11:46:18 INFO Worker: Executor app-20210228114615-0003/0 finished with state FAILED message java.io.IOException: Cannot run program "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" (in directory "/home/laal/MAG/TMP/work/app-20210228114615-0003/0"): error=2, No such file or directory
21/02/28 11:46:18 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
21/02/28 11:46:18 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228114615-0003, execId=0)
21/02/28 11:46:18 INFO Worker: Asked to launch executor app-20210228114615-0003/3 for pyspark-shell
21/02/28 11:46:18 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:18 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "2" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 11:46:18 ERROR ExecutorRunner: Error running executor
java.io.IOException: Cannot run program "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" (in directory "/home/laal/MAG/TMP/work/app-20210228114615-0003/2"): error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at org.apache.spark.deploy.worker.ExecutorRunner.org$apache$spark$deploy$worker$ExecutorRunner$$fetchAndRunExecutor(ExecutorRunner.scala:181)
	at org.apache.spark.deploy.worker.ExecutorRunner$$anon$1.run(ExecutorRunner.scala:79)
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 2 more
21/02/28 11:46:18 INFO Worker: Executor app-20210228114615-0003/2 finished with state FAILED message java.io.IOException: Cannot run program "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" (in directory "/home/laal/MAG/TMP/work/app-20210228114615-0003/2"): error=2, No such file or directory
21/02/28 11:46:18 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
21/02/28 11:46:18 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228114615-0003, execId=2)
21/02/28 11:46:18 INFO Worker: Asked to launch executor app-20210228114615-0003/4 for pyspark-shell
21/02/28 11:46:18 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:18 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:18 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:19 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "4" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 11:46:19 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "3" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.103:42397"
21/02/28 11:46:23 INFO Worker: Executor app-20210228114615-0003/1 finished with state EXITED message Command exited with code 1 exitStatus 1
21/02/28 11:46:23 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
21/02/28 11:46:23 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228114615-0003, execId=1)
21/02/28 11:46:23 INFO Worker: Asked to launch executor app-20210228114615-0003/5 for pyspark-shell
21/02/28 11:46:23 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:23 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:23 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:23 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:23 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "5" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 11:46:27 INFO Worker: Executor app-20210228114615-0003/5 finished with state EXITED message Command exited with code 1 exitStatus 1
21/02/28 11:46:27 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 5
21/02/28 11:46:27 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228114615-0003, execId=5)
21/02/28 11:46:27 INFO Worker: Asked to launch executor app-20210228114615-0003/6 for pyspark-shell
21/02/28 11:46:27 INFO Worker: Executor app-20210228114615-0003/4 finished with state EXITED message Command exited with code 1 exitStatus 1
21/02/28 11:46:27 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 4
21/02/28 11:46:27 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228114615-0003, execId=4)
21/02/28 11:46:27 INFO Worker: Asked to launch executor app-20210228114615-0003/7 for pyspark-shell
21/02/28 11:46:28 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:28 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:28 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:28 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:28 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:28 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:28 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:28 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:28 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "7" "--hostname" "172.16.16.102" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.102:43968"
21/02/28 11:46:28 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "6" "--hostname" "172.16.16.101" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.101:35812"
21/02/28 11:46:30 INFO Worker: Executor app-20210228114615-0003/3 finished with state EXITED message Command exited with code 1 exitStatus 1
21/02/28 11:46:30 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 3
21/02/28 11:46:30 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20210228114615-0003, execId=3)
21/02/28 11:46:30 INFO Worker: Asked to launch executor app-20210228114615-0003/8 for pyspark-shell
21/02/28 11:46:35 INFO SecurityManager: Changing view acls to: laal
21/02/28 11:46:35 INFO SecurityManager: Changing modify acls to: laal
21/02/28 11:46:35 INFO SecurityManager: Changing view acls groups to: 
21/02/28 11:46:35 INFO SecurityManager: Changing modify acls groups to: 
21/02/28 11:46:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/28 11:46:35 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java" "-cp" "/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/*" "-Xmx20000M" "-Dspark.driver.port=37837" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@desktop1.hpc.itu.dk:37837" "--executor-id" "8" "--hostname" "172.16.16.103" "--cores" "4" "--app-id" "app-20210228114615-0003" "--worker-url" "spark://Worker@172.16.16.103:42397"
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: Detected 1 oom-kill event(s) in step 36575.1 cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
slurmstepd: error: *** STEP 36575.1 ON desktop1 CANCELLED AT 2021-02-28T11:51:08 ***
slurmstepd: error: Detected 1 oom-kill event(s) in step 36575.1 cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
slurmstepd: error: Detected 2 oom-kill event(s) in step 36575.1 cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
slurmstepd: error: *** JOB 36575 ON desktop1 CANCELLED AT 2021-02-28T11:51:08 ***
slurmstepd: error: Detected 1 oom-kill event(s) in step 36575.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
