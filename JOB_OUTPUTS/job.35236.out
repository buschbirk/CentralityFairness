Running on desktop3:
21/02/20 17:06:35 WARN Utils: Your hostname, desktop3 resolves to a loopback address: 127.0.0.1; using 172.16.16.103 instead (on interface eno1)
21/02/20 17:06:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/20 17:06:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Traceback (most recent call last):
  File "/home/laal/MAG/CentralityFairness/sparktest.py", line 80, in <module>
    df = mag.getDataframe('Papers', 'scratch/MAG/Papers.txt')
  File "/home/laal/MAG/CentralityFairness/sparktest.py", line 48, in getDataframe
    return spark.read.format('csv').options(header='false', delimiter='\t').schema(self.getSchema(streamName)).load(filepath)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 178, in load
    return self._df(self._jreader.load(path))
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/py4j/java_gateway.py", line 1305, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/pyspark/sql/utils.py", line 134, in deco
    raise_from(converted)
  File "<string>", line 3, in raise_from
pyspark.sql.utils.AnalysisException: Path does not exist: file:/home/laal/MAG/CentralityFairness/scratch/MAG/Papers.txt;
