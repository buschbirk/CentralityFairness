Running on desktop1:
INFO:sparkhpc.sparkjob:Submitted batch job 35644

INFO:sparkhpc.sparkjob:Submitted cluster 0
Traceback (most recent call last):
  File "/home/laal/MAG/CentralityFairness/MAG_attributes_cluster.py", line 197, in <module>
    spark = sj.start_spark()
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 522, in start_spark
    sc = SparkContext(master=self.master_url(), conf=conf)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 254, in master_url
    return self._master_url(self.jobid)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 314, in _master_url
    return self._get_master(jobid, regex='(spark://\S+:\d{4})',timeout=timeout)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 294, in _get_master
    job_peek = self._peek()
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/slurmsparkjob.py", line 32, in _peek
    with open(os.path.join(self.workdir, 'sparkcluster-%s.log'%self.jobid)) as f: 
FileNotFoundError: [Errno 2] No such file or directory: '/home/laal/MAG/CentralityFairness/sparkcluster-35644.log'
