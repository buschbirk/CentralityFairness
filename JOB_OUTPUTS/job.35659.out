Running on desktop1:
I GOT THE SCHEDULER
slurm
master_command: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-master.sh
Traceback (most recent call last):
  File "/home/laal/MAG/CentralityFairness/clusterscript.py", line 14, in <module>
    spark_home='/home/laal/MAG/spark-3.0.2-bin-hadoop2.7')
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 572, in start_cluster
    nodelist.sort()
NameError: name 'nodelist' is not defined
INFO:sparkhpc.sparkjob:Submitted batch job 35660

INFO:sparkhpc.sparkjob:Submitted cluster 0
Traceback (most recent call last):
  File "/home/laal/MAG/CentralityFairness/MAG_attributes_cluster.py", line 197, in <module>
    spark = sj.start_spark()
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 522, in start_spark
    sc = SparkContext(master=self.master_url(), conf=conf)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 254, in master_url
    return self._master_url(self.jobid)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 314, in _master_url
    return self._get_master(jobid, regex='(spark://\S+:\d{4})',timeout=timeout)
  File "/home/laal/.conda/envs/torchenv/lib/python3.7/site-packages/sparkhpc/sparkjob.py", line 304, in _get_master
    raise RuntimeError('Unable to obtain information about Spark master -- are you sure it is running?')
RuntimeError: Unable to obtain information about Spark master -- are you sure it is running?
