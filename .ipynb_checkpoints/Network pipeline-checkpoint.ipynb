{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flush-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MAG_network import CitationNetwork\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import findspark\n",
    "import MAGspark \n",
    "\n",
    "# set environment variables\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"/home/laal/MAG/TMP\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64\"\n",
    "os.environ['SPARK_HOME'] = \"/home/laal/MAG/spark-3.0.2-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporate-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAME STATE JOBID', 'covid19tweets PENDING 39636', 'covid19tweets PENDING 39637', 'hyperopt PENDING 39677', 'hyperopt PENDING 39678', 'hyperopt RUNNING 39676', 'sparkcluster RUNNING 39715', 'hyperopt RUNNING 39675', 'jupyter RUNNING 39764', 'hyperopt RUNNING 39673', 'hyperopt RUNNING 39674', 'piano RUNNING 39738', 'resume6_ccmfotw_roberta_base_fp16_1M RUNNING 39633', 'resume7_ccs_roberta_base_fp16_1M RUNNING 39634', 'resume5_cc13_roberta_base_fp16_1M RUNNING 39632', 'tmp_with_c_ct RUNNING 39712', 'tmp_with_c_ct RUNNING 39711', 'tmp_with_c_ct RUNNING 39710', 'tmp_ct RUNNING 39707', 'tmp_ct RUNNING 39708', '']\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org.apache.spark.api.python.PythonUtils.getPythonAuthSocketTimeout does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-deac00e37053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mag, spark = MAGspark.get_mag_with_cluster_connection(jobid=39715, memory_per_executor=14000,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                         data_folderpath=\"/home/laal/MAG/DATA/\")\n",
      "\u001b[0;32m~/MAG/CentralityFairness/MAGspark.py\u001b[0m in \u001b[0;36mget_mag_with_cluster_connection\u001b[0;34m(jobid, memory_per_executor, data_folderpath)\u001b[0m\n\u001b[1;32m     56\u001b[0m                                     data_folderpath=\"/home/laal/MAG/DATA/\"):\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cluster_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m39181\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_per_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mmag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMicrosoftAcademicGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_folderpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/laal/MAG/DATA/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MAG/CentralityFairness/MAGspark.py\u001b[0m in \u001b[0;36mget_cluster_client\u001b[0;34m(jobid, memory_per_executor)\u001b[0m\n\u001b[1;32m     32\u001b[0m     }\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gtenv/lib/python3.9/site-packages/sparkhpc/sparkjob.py\u001b[0m in \u001b[0;36mstart_spark\u001b[0;34m(self, spark_conf, executor_memory, profiling, graphframes_package, extra_conf)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gtenv/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0m\u001b[1;32m    147\u001b[0m                           conf, jsc, profiler_cls)\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gtenv/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encryption_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEncryptionEnabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPARK_AUTH_SOCKET_TIMEOUT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPythonAuthSocketTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPARK_BUFFER_SIZE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSparkBufferSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gtenv/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1528\u001b[0m                     answer, self._gateway_client, self._fqn, name)\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m   1531\u001b[0m                 \"{0}.{1} does not exist in the JVM\".format(self._fqn, name))\n\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: org.apache.spark.api.python.PythonUtils.getPythonAuthSocketTimeout does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "mag, spark = MAGspark.get_mag_with_cluster_connection(jobid=39715, memory_per_executor=14000,\n",
    "                                                      data_folderpath=\"/home/laal/MAG/DATA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-algeria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
