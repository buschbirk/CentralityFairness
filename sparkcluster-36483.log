Running on desktop1:
INFO:sparkhpc.sparkjob:master command: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-master.sh
INFO:sparkhpc.sparkjob:[[92mstart_cluster] [0mmaster running at spark://172.16.16.101:7077
INFO:sparkhpc.sparkjob:[[92mstart_cluster] [0mmaster UI available at http://desktop1.hpc.itu.dk:8080
What is going on
I GOT THE SCHEDULER
slurm
master_command: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-master.sh
['desktop1', 'desktop2', 'desktop3']
INFO:sparkhpc.sparkjob:slaves command: srun /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-slave.sh spark://172.16.16.101:7077 -c 4
INFO:sparkhpc.sparkjob:XXX SLAVES SLAVES: srun /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/sbin/start-slave.sh spark://172.16.16.101:7077 -c 4
starting org.apache.spark.deploy.worker.Worker, logging to /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/logs/spark-laal-org.apache.spark.deploy.worker.Worker-1-desktop1.out
starting org.apache.spark.deploy.worker.Worker, logging to /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/logs/spark-laal-org.apache.spark.deploy.worker.Worker-1-desktop1.out
starting org.apache.spark.deploy.worker.Worker, logging to /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/logs/spark-laal-org.apache.spark.deploy.worker.Worker-1-desktop1.out
Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java -cp /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://172.16.16.101:7077 -c 4
========================================
Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java -cp /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://172.16.16.101:7077 -c 4
========================================
Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/bin/java -cp /home/laal/MAG/spark-3.0.2-bin-hadoop2.7/conf/:/home/laal/MAG/spark-3.0.2-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://172.16.16.101:7077 -c 4
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/26 17:37:56 INFO Worker: Started daemon with process name: 24153@desktop1
21/02/26 17:37:56 INFO SignalUtils: Registered signal handler for TERM
21/02/26 17:37:56 INFO SignalUtils: Registered signal handler for HUP
21/02/26 17:37:56 INFO SignalUtils: Registered signal handler for INT
21/02/26 17:37:56 WARN Utils: Your hostname, desktop1 resolves to a loopback address: 127.0.0.1; using 172.16.16.101 instead (on interface eno1)
21/02/26 17:37:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/26 17:37:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/26 17:37:56 INFO SecurityManager: Changing view acls to: laal
21/02/26 17:37:56 INFO SecurityManager: Changing modify acls to: laal
21/02/26 17:37:56 INFO SecurityManager: Changing view acls groups to: 
21/02/26 17:37:56 INFO SecurityManager: Changing modify acls groups to: 
21/02/26 17:37:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/26 17:37:56 INFO Utils: Successfully started service 'sparkWorker' on port 39855.
21/02/26 17:37:57 INFO Worker: Starting Spark worker 172.16.16.101:39855 with 4 cores, 5.9 GiB RAM
21/02/26 17:37:57 INFO Worker: Running Spark version 3.0.2
21/02/26 17:37:57 INFO Worker: Spark home: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7
21/02/26 17:37:57 INFO ResourceUtils: ==============================================================
21/02/26 17:37:57 INFO ResourceUtils: Resources for spark.worker:

21/02/26 17:37:57 INFO ResourceUtils: ==============================================================
21/02/26 17:37:57 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/02/26 17:37:57 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://desktop1.hpc.itu.dk:8081
21/02/26 17:37:57 INFO Worker: Connecting to master 172.16.16.101:7077...
21/02/26 17:37:57 INFO TransportClientFactory: Successfully created connection to /172.16.16.101:7077 after 30 ms (0 ms spent in bootstraps)
21/02/26 17:37:57 INFO Worker: Successfully registered with master spark://172.16.16.101:7077
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/26 17:37:58 INFO Worker: Started daemon with process name: 6673@desktop3
21/02/26 17:37:58 INFO SignalUtils: Registered signal handler for TERM
21/02/26 17:37:58 INFO SignalUtils: Registered signal handler for HUP
21/02/26 17:37:58 INFO SignalUtils: Registered signal handler for INT
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/02/26 17:37:58 INFO Worker: Started daemon with process name: 2852@desktop2
21/02/26 17:37:58 WARN Utils: Your hostname, desktop3 resolves to a loopback address: 127.0.0.1; using 172.16.16.103 instead (on interface eno1)
21/02/26 17:37:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/26 17:37:58 INFO SignalUtils: Registered signal handler for TERM
21/02/26 17:37:58 INFO SignalUtils: Registered signal handler for HUP
21/02/26 17:37:58 INFO SignalUtils: Registered signal handler for INT
21/02/26 17:37:58 WARN Utils: Your hostname, desktop2 resolves to a loopback address: 127.0.0.1; using 172.16.16.102 instead (on interface eno1)
21/02/26 17:37:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/02/26 17:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/26 17:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/26 17:37:58 INFO SecurityManager: Changing view acls to: laal
21/02/26 17:37:58 INFO SecurityManager: Changing modify acls to: laal
21/02/26 17:37:58 INFO SecurityManager: Changing view acls groups to: 
21/02/26 17:37:58 INFO SecurityManager: Changing modify acls groups to: 
21/02/26 17:37:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/26 17:37:58 INFO SecurityManager: Changing view acls to: laal
21/02/26 17:37:58 INFO SecurityManager: Changing modify acls to: laal
21/02/26 17:37:58 INFO SecurityManager: Changing view acls groups to: 
21/02/26 17:37:58 INFO SecurityManager: Changing modify acls groups to: 
21/02/26 17:37:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(laal); groups with view permissions: Set(); users  with modify permissions: Set(laal); groups with modify permissions: Set()
21/02/26 17:37:59 INFO Utils: Successfully started service 'sparkWorker' on port 33657.
21/02/26 17:37:59 INFO Utils: Successfully started service 'sparkWorker' on port 46882.
21/02/26 17:37:59 INFO Worker: Starting Spark worker 172.16.16.103:33657 with 4 cores, 5.9 GiB RAM
21/02/26 17:37:59 INFO Worker: Running Spark version 3.0.2
21/02/26 17:37:59 INFO Worker: Spark home: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7
21/02/26 17:37:59 INFO ResourceUtils: ==============================================================
21/02/26 17:37:59 INFO ResourceUtils: Resources for spark.worker:

21/02/26 17:37:59 INFO ResourceUtils: ==============================================================
21/02/26 17:37:59 INFO Worker: Starting Spark worker 172.16.16.102:46882 with 4 cores, 5.9 GiB RAM
21/02/26 17:37:59 INFO Worker: Running Spark version 3.0.2
21/02/26 17:37:59 INFO Worker: Spark home: /home/laal/MAG/spark-3.0.2-bin-hadoop2.7
21/02/26 17:37:59 INFO ResourceUtils: ==============================================================
21/02/26 17:37:59 INFO ResourceUtils: Resources for spark.worker:

21/02/26 17:37:59 INFO ResourceUtils: ==============================================================
21/02/26 17:37:59 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/02/26 17:37:59 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://desktop3.hpc.itu.dk:8081
21/02/26 17:37:59 INFO Worker: Connecting to master 172.16.16.101:7077...
21/02/26 17:37:59 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
21/02/26 17:37:59 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://desktop2.hpc.itu.dk:8081
21/02/26 17:37:59 INFO Worker: Connecting to master 172.16.16.101:7077...
21/02/26 17:37:59 INFO TransportClientFactory: Successfully created connection to /172.16.16.101:7077 after 23 ms (0 ms spent in bootstraps)
21/02/26 17:37:59 INFO Worker: Successfully registered with master spark://172.16.16.101:7077
21/02/26 17:37:59 INFO TransportClientFactory: Successfully created connection to /172.16.16.101:7077 after 27 ms (0 ms spent in bootstraps)
21/02/26 17:37:59 INFO Worker: Successfully registered with master spark://172.16.16.101:7077
